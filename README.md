# ğŸ¤– LMstudio Model Config Recommender

**LMstudio Model Config Recommender** is an interactive Python tool that recommends optimal configuration settings for running Large Language Models (LLMs) inside [LM Studio](https://lmstudio.ai), tailored to your **hardware specs** and **model usage goals**.

Whether you're aiming for maximum creativity, high accuracy, or resource-efficient inference, this tool helps generate the right settings for parameters like:

- `context length`
- `batch size`
- `temperature`
- `top-k`
- `top-p`
- `repeat penalty`
- and more

---

## ğŸ”§ Key Features

- ğŸ§  Auto-detects system hardware (CPU, GPU, RAM)
- ğŸ¤– Asks user-friendly questions to infer usage intent (e.g. creativity vs. precision)
- ğŸ“Š Suggests performance-aware values for critical LLM runtime parameters
- ğŸ“ Outputs ready-to-use YAML config for LM Studio
- ğŸ§° Works across macOS, Linux, and Windows

---

## ğŸ“‚ Project Structure

```plaintext
LMstudio-model-config-recommender/
â”‚
â”œâ”€â”€ cli.py                  # Command-line interface
â”œâ”€â”€ hardware\_utils.py       # Detect system specs
â”œâ”€â”€ model\_profile.py        # Ask for usage preferences
â”œâ”€â”€ recommender.py          # Generate config from inputs
â”œâ”€â”€ templates/              # Output YAML templates
â”œâ”€â”€ output/                 # Generated configs
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## ğŸš€ How to Use

### 1. Set up the environment

```bash
git clone https://github.com/your-username/LMstudio-model-config-recommender.git
cd LMstudio-model-config-recommender

python -m venv venv
source venv/bin/activate   # or use venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 2. Run the tool

```bash
python cli.py --export output/lmstudio_config.yaml
```

Youâ€™ll be guided through:

- detecting your hardware (CPU, RAM, GPU)
- choosing your model or upload path
- expressing your intent (e.g. â€œI need creative writingâ€ or â€œI care about precisionâ€)

ğŸ’¾ Your recommended configuration will be saved to `output/lmstudio_config.yaml`

---

## ğŸ’¡ Example Use Cases

- "I want to run **Mistral-7B** on my **16GB RAM MacBook** â€” whatâ€™s the right context size?"
- "I'm prioritizing **accuracy** over speed â€” what settings should I change?"
- "How do I configure **temperature** or **top-p** for **creative content generation**?"

This tool takes the guesswork out of configuring models and adapts to your local resources.

---

## ğŸ“ˆ Roadmap

- [x] Cross-platform support (Linux/macOS/Windows)
- [x] Basic interactive CLI
- [x] Hardware auto-detection
- [ ] GUI using `streamlit` or `textual`
- [ ] Config preview before export
- [ ] Model library with presets (e.g. LLaMA 3, Mistral, Gemma, Mixtral)

---

## ğŸ¤ Contributing

We welcome PRs and suggestions!
To contribute:

1. Fork the repo
2. Create a new branch
3. Submit your pull request

A `CONTRIBUTING.md` guide will be added soon.

---

## ğŸ§‘â€ğŸ’» Maintainers

Developed by [@ghaffaria](https://github.com/ghaffaria).
Inspired by the challenges of configuring local LLMs properly.

---

## ğŸ“„ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).
